{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ec35a-2fae-4998-ace6-1f0fec1c9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jorge Barcia Belinchón 100496595 partner Paloma Núñez Guerrero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad115d-8590-4f6e-adee-8407604d4d02",
   "metadata": {
    "id": "7fad115d-8590-4f6e-adee-8407604d4d02"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b96dc-fef7-476f-9724-9be9c8b302ba",
   "metadata": {
    "id": "a54b96dc-fef7-476f-9724-9be9c8b302ba"
   },
   "outputs": [],
   "source": [
    "# Function of numpy we have used\n",
    "#    1. To create matrix: np.random.rand()\n",
    "#    2. Verify if the matrix if invertible:\n",
    "#           numpy.linalg.det() (det 0 is not invertible)\n",
    "#    3. Verify result: numpy.allclose()\n",
    "#    4. Multiplication: numpy.dot()\n",
    "#    5. Manipulation: numpy.transpose(), numpy.reshape(), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798ba32-4237-475b-8ceb-867e60550072",
   "metadata": {
    "id": "1798ba32-4237-475b-8ceb-867e60550072"
   },
   "source": [
    "# Create initial matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0526e-8452-44ab-aaac-27cd34fcf6b6",
   "metadata": {
    "id": "36c0526e-8452-44ab-aaac-27cd34fcf6b6"
   },
   "source": [
    "Variables to change:\n",
    "* numN: number of rows-columns of the matrix\n",
    "* min_value: min value in the matrix\n",
    "* max_value: max value in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df039c8-da90-4665-8f98-69f92f4cac73",
   "metadata": {
    "id": "1df039c8-da90-4665-8f98-69f92f4cac73"
   },
   "outputs": [],
   "source": [
    "# First of all, create the matrix\n",
    "def create_matrix(numN, min_value, max_value, int_matrix=False):\n",
    "    matrix_good = False\n",
    "    matrix = np.zeros((numN, numN))\n",
    "    while not matrix_good:\n",
    "        # Generate matrix\n",
    "        if int_matrix:\n",
    "            matrix = np.random.randint(low=min_value, high=max_value, size=(numN, numN))\n",
    "        else:\n",
    "            matrix = np.random.rand(numN, numN) * (max_value - min_value) + min_value\n",
    "\n",
    "        # Check if it's invertible\n",
    "        determinant = np.linalg.det(matrix)\n",
    "        if determinant != 0 and not np.isinf(determinant) and not np.isnan(determinant):\n",
    "            matrix_good = True\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed48f3-a0cf-4b11-8d50-49c02034a66a",
   "metadata": {
    "id": "51ed48f3-a0cf-4b11-8d50-49c02034a66a"
   },
   "outputs": [],
   "source": [
    "# Set the num cores\n",
    "NUMREPORTEDCORES=mp.cpu_count()\n",
    "#Should be the number of real computational cores\n",
    "NUMCORES=NUMREPORTEDCORES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27f3c5-9671-462e-9839-ce17972e0e19",
   "metadata": {
    "id": "9b27f3c5-9671-462e-9839-ce17972e0e19"
   },
   "source": [
    "# Practical Work 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26949b-2638-45ff-86e3-481320d5c756",
   "metadata": {
    "id": "4d26949b-2638-45ff-86e3-481320d5c756"
   },
   "outputs": [],
   "source": [
    "def init_sharedarray(shared_array, matrix_shape, minors_array, cofactor_array):\n",
    "    #global shared_space\n",
    "    global shared_matrix\n",
    "    global matrix_lock\n",
    "    global shared_minors_matrix\n",
    "    global shared_cofactor_matrix\n",
    "\n",
    "    shared_matrix = np.frombuffer(shared_array.get_obj(), dtype=np.float64).reshape(matrix_shape)\n",
    "    shared_minors_matrix = np.frombuffer(minors_array.get_obj(), dtype=np.float64).reshape(matrix_shape)\n",
    "    shared_cofactor_matrix = np.frombuffer(cofactor_array.get_obj(), dtype=np.float64).reshape(matrix_shape)\n",
    "    matrix_lock = mp.Lock()\n",
    "\n",
    "\n",
    "class InversedMatrix:\n",
    "\n",
    "  def __init__(self, matrix):\n",
    "      self.matrix = matrix\n",
    "      self.num_rows, self.num_cols = matrix.shape\n",
    "      self.shared_array = mp.Array('d', self.num_rows * self.num_cols)\n",
    "      self.shared_minors_matrix_space = mp.Array('d', self.num_rows * self.num_cols)\n",
    "      self.shared_cofactor_matrix_space = mp.Array('d', self.num_rows * self.num_cols)\n",
    "\n",
    "      self.copy_matrix_to_shared()\n",
    "\n",
    "  def copy_matrix_to_shared(self):\n",
    "      np.copyto(np.frombuffer(self.shared_array.get_obj(), dtype=np.float64).reshape((self.num_rows, self.num_cols)), self.matrix.astype(np.float64))\n",
    "\n",
    "  # ------------ STEP 1 ------------\n",
    "  @staticmethod\n",
    "  def calculate_determinant_minor(matrix, row, column):\n",
    "      # Eliminate row and column indicated\n",
    "      submatrix = np.delete(np.delete(matrix, row, axis=0), column, axis=1)\n",
    "      return np.linalg.det(submatrix)\n",
    "\n",
    "  @staticmethod\n",
    "  def compute_minor(row):\n",
    "      global shared_matrix\n",
    "      global shared_minors_matrix\n",
    "      global matrix_lock\n",
    "\n",
    "      num_cols = shared_matrix.shape[1]\n",
    "      local_minors_row = np.zeros(num_cols)\n",
    "\n",
    "      for column in range(num_cols):\n",
    "          local_minors_row[column] = InversedMatrix.calculate_determinant_minor(shared_matrix, row, column)\n",
    "\n",
    "\n",
    "      with matrix_lock:\n",
    "          shared_minors_matrix[row, :] = local_minors_row\n",
    "\n",
    "  # Calculate minor matrix\n",
    "  def calculate_minors_matrix(self):\n",
    "      rows = range(self.num_rows)\n",
    "\n",
    "      with mp.Pool(processes=NUMCORES, initializer=init_sharedarray,\n",
    "                     initargs=[self.shared_array, (self.num_rows, self.num_cols), self.shared_minors_matrix_space, self.shared_cofactor_matrix_space]) as pool:\n",
    "            pool.map(self.compute_minor, rows)\n",
    "\n",
    "      # Convert to numpy array\n",
    "      minors_matrix = np.frombuffer(self.shared_minors_matrix_space.get_obj(), dtype=np.float64).reshape((self.num_rows, self.num_cols))\n",
    "\n",
    "      return minors_matrix\n",
    "\n",
    "\n",
    "  # ------------ STEP 2 ------------\n",
    "  # Not neccesary to do paralellization, but the method is more optimal, which is what we seek.\n",
    "  \"\"\"@staticmethod\n",
    "  def calculate_cofactor_matrix(minors_matrix):\n",
    "      sign_matrix = np.fromfunction(lambda i, j: (-1) ** (i + j), minors_matrix.shape, dtype=int)\n",
    "\n",
    "      cofactor_matrix = minors_matrix * sign_matrix\n",
    "\n",
    "      return cofactor_matrix\"\"\"\n",
    "\n",
    "  @staticmethod\n",
    "  def compute_cofactor_element(row_col):\n",
    "      global shared_minors_matrix\n",
    "      global shared_cofactor_matrix\n",
    "      global matrix_lock\n",
    "\n",
    "      row, col = row_col\n",
    "      sign = (-1) ** (row + col)\n",
    "\n",
    "      cofactor_value = sign * shared_minors_matrix[row, col]\n",
    "\n",
    "      with matrix_lock:\n",
    "          shared_cofactor_matrix[row, col] = cofactor_value\n",
    "\n",
    "  def calculate_cofactor_matrix(self):\n",
    "      indices = [(row, col) for row in range(self.num_rows) for col in range(self.num_cols)]\n",
    "\n",
    "      with mp.Pool(processes=NUMCORES, initializer=init_sharedarray,\n",
    "                    initargs=[self.shared_array, (self.num_rows, self.num_cols), self.shared_minors_matrix_space, self.shared_cofactor_matrix_space]) as pool:\n",
    "          pool.map(InversedMatrix.compute_cofactor_element, indices)\n",
    "\n",
    "      cofactor_matrix = np.frombuffer(self.shared_cofactor_matrix_space.get_obj(), dtype=np.float64).reshape((self.num_rows, self.num_cols))\n",
    "      return cofactor_matrix\n",
    "\n",
    "\n",
    " # ------------ STEP 3 ------------\n",
    "  @staticmethod\n",
    "  def calculate_adjugate(cofactor_matrix):\n",
    "    return np.transpose(cofactor_matrix)\n",
    "\n",
    "\n",
    " # ------------ STEP 4 ------------\n",
    "def calculate_inverse(matrix_A):\n",
    "    inverse = InversedMatrix(matrix_A)\n",
    "\n",
    "    determinant = np.linalg.det(matrix_A)\n",
    "\n",
    "    minors_matrix = inverse.calculate_minors_matrix()\n",
    "    cofactor_matrix = inverse.calculate_cofactor_matrix()\n",
    "    adjugate_matrix = inverse.calculate_adjugate(cofactor_matrix)\n",
    "\n",
    "    \"\"\"print(\"Original matrix:\")\n",
    "    print(matrix_A)\n",
    "    print(\"\\nMinors matrix:\")\n",
    "    print(minors_matrix)\n",
    "    print(\"\\nCofactor matrix:\")\n",
    "    print(cofactor_matrix)\n",
    "    print(\"\\nMAdjugate matrix:\")\n",
    "    print(adjugate_matrix)\"\"\"\n",
    "\n",
    "    return adjugate_matrix / determinant\n",
    "\n",
    "# ------------ EVALUATION ------------\n",
    "def check_inverse(original_matrix, inverse_matrix):\n",
    "    identity_matrix = np.eye(original_matrix.shape[0])\n",
    "\n",
    "    product = np.dot(original_matrix, inverse_matrix)\n",
    "\n",
    "    return np.allclose(product, identity_matrix, atol=1e-10, rtol=1e-10)\n",
    "\n",
    "def performance_test(numN, min_value, max_value, iterations=10):\n",
    "    total_time = 0\n",
    "    for _ in range(iterations):\n",
    "        matrix_A = create_matrix(numN, min_value, max_value)\n",
    "\n",
    "        start_time = time.time()\n",
    "        inverse_matrix = calculate_inverse(matrix_A)\n",
    "        end_time = time.time()\n",
    "\n",
    "        is_correct = check_inverse(matrix_A, inverse_matrix)\n",
    "        print(\"\\n¿The inverse is correct?\", is_correct)\n",
    "\n",
    "        total_time += (end_time - start_time)\n",
    "\n",
    "    average_time = total_time / iterations\n",
    "    print(f\"Tamaño de la matriz: {numN}x{numN}, tiempo promedio para calcular la inversa: {average_time:.4f} segundos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RSZTOUk4TDb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSZTOUk4TDb1",
    "outputId": "eff451f4-2b60-4ffe-ecea-09d8b694ddd9"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "    numN=500\n",
    "    min_value = -0.25 #-1000\n",
    "    max_value = 0.25 # 1000\n",
    "\n",
    "    # for one: iterations = 1\n",
    "    \n",
    "    performance_test(numN, min_value, max_value, iterations=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f392b-d668-452d-bf1c-1d35cf08d765",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Conclusion: \n",
    " > The work consisted of four parts, the most complicated of which was the first. \n",
    "At first, we did not manage to get the values stored in the minors array, so the variable was introduced in the init_sharedarray() function. After that, we faced running problems, and to solve this we introduced the variable in the init_sharedarray() function.\n",
    "---\n",
    "> After that, we were confronted with race problems, and locks were introduced to solve them. Finally, to finish the first step, attention was paid to memory accesses, trying to reduce them as much as possible.\n",
    "Moving on to the second step, although it is not necessary to parallelise it, it was done to reduce memory accesses, so that when large arrays are used, it is as fast as possible. Similarly, the function that does not contain parallelisation has been kept commented out.\n",
    "---\n",
    "> To execute the whole loop, the main must be executed, so that the number of iterations, the size of the matrix, and the range of values it must contain are established."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fcf1d-0a27-48e3-bb84-9a0d3f50a805",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    " > For this work we have follow a by parts aproach, being the first one the hardest as it required some majors changes of our initial aproach especificaly in storing values in the minors array and some running problems, this problems were solve by introducing them in the init_sharedarray() function.\n",
    "> the next step was solving with the race problem that was fairly discus truh out the course therefore using locks was a straigh forwar solution. After implementing locks we needed to implement the memory access in the smartes way possible to not consume to many resources.\n",
    ">The next part was to parallelise the proces to improve performance and reduce memory access.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3dbb1e-0fce-4f6b-9b5b-216a81b74344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
